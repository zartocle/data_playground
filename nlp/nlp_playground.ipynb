{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing\n",
    "\n",
    "#### As seen on the [Python-Natural-Language-Processing-Cookbook](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook/tree/master)\n",
    "\n",
    "#### Chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ale/git/main/nlp'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "my_filename = \"Python-Natural-Language-Processing-Cookbook/Chapter01/sherlock_holmes_1.txt\"\n",
    "my_file = open( my_filename, 'r', encoding='utf-8' )\n",
    "text = my_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiize an NLTK tokenizer using the PUNKT model\n",
    "tokenizer_instance = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To Sherlock Holmes she is always _the_ woman.',\n",
       " 'I have seldom heard him mention her under any other name.',\n",
       " 'In his eyes she eclipses and predominates the whole of her sex.',\n",
       " 'It was not that he felt any emotion akin to love for Irene Adler.',\n",
       " 'All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.',\n",
       " 'He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position.',\n",
       " 'He never spoke of the softer passions, save with a gibe and a sneer.',\n",
       " 'They were admirable things for the observer—excellent for drawing the veil from men’s motives and actions.',\n",
       " 'But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results.',\n",
       " 'Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his.',\n",
       " 'And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide text into sentences:\n",
    "sentences_output = tokenizer_instance.tokenize( text )\n",
    "sentences_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To',\n",
       " 'Sherlock',\n",
       " 'Holmes',\n",
       " 'she',\n",
       " 'is',\n",
       " 'always',\n",
       " '_the_',\n",
       " 'woman',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'seldom',\n",
       " 'heard',\n",
       " 'him',\n",
       " 'mention',\n",
       " 'her',\n",
       " 'under',\n",
       " 'any',\n",
       " 'other',\n",
       " 'name',\n",
       " '.',\n",
       " 'In',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'she',\n",
       " 'eclipses',\n",
       " 'and',\n",
       " 'predominates',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'of',\n",
       " 'her',\n",
       " 'sex',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'not',\n",
       " 'that',\n",
       " 'he',\n",
       " 'felt',\n",
       " 'any',\n",
       " 'emotion',\n",
       " 'akin',\n",
       " 'to',\n",
       " 'love',\n",
       " 'for',\n",
       " 'Irene',\n",
       " 'Adler',\n",
       " '.',\n",
       " 'All',\n",
       " 'emotions',\n",
       " ',',\n",
       " 'and',\n",
       " 'that',\n",
       " 'one',\n",
       " 'particularly',\n",
       " ',',\n",
       " 'were',\n",
       " 'abhorrent',\n",
       " 'to',\n",
       " 'his',\n",
       " 'cold',\n",
       " ',',\n",
       " 'precise',\n",
       " 'but',\n",
       " 'admirably',\n",
       " 'balanced',\n",
       " 'mind',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " ',',\n",
       " 'I',\n",
       " 'take',\n",
       " 'it',\n",
       " ',',\n",
       " 'the',\n",
       " 'most',\n",
       " 'perfect',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'observing',\n",
       " 'machine',\n",
       " 'that',\n",
       " 'the',\n",
       " 'world',\n",
       " 'has',\n",
       " 'seen',\n",
       " ',',\n",
       " 'but',\n",
       " 'as',\n",
       " 'a',\n",
       " 'lover',\n",
       " 'he',\n",
       " 'would',\n",
       " 'have',\n",
       " 'placed',\n",
       " 'himself',\n",
       " 'in',\n",
       " 'a',\n",
       " 'false',\n",
       " 'position',\n",
       " '.',\n",
       " 'He',\n",
       " 'never',\n",
       " 'spoke',\n",
       " 'of',\n",
       " 'the',\n",
       " 'softer',\n",
       " 'passions',\n",
       " ',',\n",
       " 'save',\n",
       " 'with',\n",
       " 'a',\n",
       " 'gibe',\n",
       " 'and',\n",
       " 'a',\n",
       " 'sneer',\n",
       " '.',\n",
       " 'They',\n",
       " 'were',\n",
       " 'admirable',\n",
       " 'things',\n",
       " 'for',\n",
       " 'the',\n",
       " 'observer—excellent',\n",
       " 'for',\n",
       " 'drawing',\n",
       " 'the',\n",
       " 'veil',\n",
       " 'from',\n",
       " 'men',\n",
       " '’',\n",
       " 's',\n",
       " 'motives',\n",
       " 'and',\n",
       " 'actions',\n",
       " '.',\n",
       " 'But',\n",
       " 'for',\n",
       " 'the',\n",
       " 'trained',\n",
       " 'reasoner',\n",
       " 'to',\n",
       " 'admit',\n",
       " 'such',\n",
       " 'intrusions',\n",
       " 'into',\n",
       " 'his',\n",
       " 'own',\n",
       " 'delicate',\n",
       " 'and',\n",
       " 'finely',\n",
       " 'adjusted',\n",
       " 'temperament',\n",
       " 'was',\n",
       " 'to',\n",
       " 'introduce',\n",
       " 'a',\n",
       " 'distracting',\n",
       " 'factor',\n",
       " 'which',\n",
       " 'might',\n",
       " 'throw',\n",
       " 'a',\n",
       " 'doubt',\n",
       " 'upon',\n",
       " 'all',\n",
       " 'his',\n",
       " 'mental',\n",
       " 'results',\n",
       " '.',\n",
       " 'Grit',\n",
       " 'in',\n",
       " 'a',\n",
       " 'sensitive',\n",
       " 'instrument',\n",
       " ',',\n",
       " 'or',\n",
       " 'a',\n",
       " 'crack',\n",
       " 'in',\n",
       " 'one',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'high-power',\n",
       " 'lenses',\n",
       " ',',\n",
       " 'would',\n",
       " 'not',\n",
       " 'be',\n",
       " 'more',\n",
       " 'disturbing',\n",
       " 'than',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'emotion',\n",
       " 'in',\n",
       " 'a',\n",
       " 'nature',\n",
       " 'such',\n",
       " 'as',\n",
       " 'his',\n",
       " '.',\n",
       " 'And',\n",
       " 'yet',\n",
       " 'there',\n",
       " 'was',\n",
       " 'but',\n",
       " 'one',\n",
       " 'woman',\n",
       " 'to',\n",
       " 'him',\n",
       " ',',\n",
       " 'and',\n",
       " 'that',\n",
       " 'woman',\n",
       " 'was',\n",
       " 'the',\n",
       " 'late',\n",
       " 'Irene',\n",
       " 'Adler',\n",
       " ',',\n",
       " 'of',\n",
       " 'dubious',\n",
       " 'and',\n",
       " 'questionable',\n",
       " 'memory',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide text into words\n",
    "words_output = nltk.tokenize.word_tokenize( text )\n",
    "words_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Central', 'Park', 'Tower', 'is', 'reaaally', 'hiiigh']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = \"@EmpireStateBldg Central Park Tower is reaaaaaaaaaally hiiiiiiiiigh\"\n",
    "tweet_words = nltk.tokenize.casual.casual_tokenize( tweet,\n",
    "                                                   preserve_case=True,\n",
    "                                                   reduce_len=True,\n",
    "                                                   strip_handles=True)\n",
    "tweet_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To',\n",
       " 'Sherlock',\n",
       " 'Holmes',\n",
       " 'she',\n",
       " 'is',\n",
       " 'always',\n",
       " '_',\n",
       " 'the',\n",
       " '_',\n",
       " 'woman',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'seldom',\n",
       " 'heard',\n",
       " 'him',\n",
       " 'mention',\n",
       " 'her',\n",
       " 'under',\n",
       " 'any',\n",
       " 'other',\n",
       " 'name',\n",
       " '.',\n",
       " 'In',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'she',\n",
       " 'eclipses',\n",
       " 'and',\n",
       " 'predominates',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'of',\n",
       " 'her',\n",
       " 'sex',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'not',\n",
       " 'that',\n",
       " 'he',\n",
       " 'felt',\n",
       " 'any',\n",
       " 'emotion',\n",
       " 'akin',\n",
       " 'to',\n",
       " 'love',\n",
       " 'for',\n",
       " 'Irene',\n",
       " 'Adler',\n",
       " '.',\n",
       " 'All',\n",
       " 'emotions',\n",
       " ',',\n",
       " 'and',\n",
       " 'that',\n",
       " 'one',\n",
       " 'particularly',\n",
       " ',',\n",
       " 'were',\n",
       " 'abhorrent',\n",
       " 'to',\n",
       " 'his',\n",
       " 'cold',\n",
       " ',',\n",
       " 'precise',\n",
       " 'but',\n",
       " 'admirably',\n",
       " 'balanced',\n",
       " 'mind',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " ',',\n",
       " 'I',\n",
       " 'take',\n",
       " 'it',\n",
       " ',',\n",
       " 'the',\n",
       " 'most',\n",
       " 'perfect',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'observing',\n",
       " 'machine',\n",
       " 'that',\n",
       " 'the',\n",
       " 'world',\n",
       " 'has',\n",
       " 'seen',\n",
       " ',',\n",
       " 'but',\n",
       " 'as',\n",
       " 'a',\n",
       " 'lover',\n",
       " 'he',\n",
       " 'would',\n",
       " 'have',\n",
       " 'placed',\n",
       " 'himself',\n",
       " 'in',\n",
       " 'a',\n",
       " 'false',\n",
       " 'position',\n",
       " '.',\n",
       " 'He',\n",
       " 'never',\n",
       " 'spoke',\n",
       " 'of',\n",
       " 'the',\n",
       " 'softer',\n",
       " 'passions',\n",
       " ',',\n",
       " 'save',\n",
       " 'with',\n",
       " 'a',\n",
       " 'gibe',\n",
       " 'and',\n",
       " 'a',\n",
       " 'sneer',\n",
       " '.',\n",
       " 'They',\n",
       " 'were',\n",
       " 'admirable',\n",
       " 'things',\n",
       " 'for',\n",
       " 'the',\n",
       " 'observer',\n",
       " '—',\n",
       " 'excellent',\n",
       " 'for',\n",
       " 'drawing',\n",
       " 'the',\n",
       " 'veil',\n",
       " 'from',\n",
       " 'men',\n",
       " '’s',\n",
       " 'motives',\n",
       " 'and',\n",
       " 'actions',\n",
       " '.',\n",
       " 'But',\n",
       " 'for',\n",
       " 'the',\n",
       " 'trained',\n",
       " 'reasoner',\n",
       " 'to',\n",
       " 'admit',\n",
       " 'such',\n",
       " 'intrusions',\n",
       " 'into',\n",
       " 'his',\n",
       " 'own',\n",
       " 'delicate',\n",
       " 'and',\n",
       " 'finely',\n",
       " 'adjusted',\n",
       " 'temperament',\n",
       " 'was',\n",
       " 'to',\n",
       " 'introduce',\n",
       " 'a',\n",
       " 'distracting',\n",
       " 'factor',\n",
       " 'which',\n",
       " 'might',\n",
       " 'throw',\n",
       " 'a',\n",
       " 'doubt',\n",
       " 'upon',\n",
       " 'all',\n",
       " 'his',\n",
       " 'mental',\n",
       " 'results',\n",
       " '.',\n",
       " 'Grit',\n",
       " 'in',\n",
       " 'a',\n",
       " 'sensitive',\n",
       " 'instrument',\n",
       " ',',\n",
       " 'or',\n",
       " 'a',\n",
       " 'crack',\n",
       " 'in',\n",
       " 'one',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'high',\n",
       " '-',\n",
       " 'power',\n",
       " 'lenses',\n",
       " ',',\n",
       " 'would',\n",
       " 'not',\n",
       " 'be',\n",
       " 'more',\n",
       " 'disturbing',\n",
       " 'than',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'emotion',\n",
       " 'in',\n",
       " 'a',\n",
       " 'nature',\n",
       " 'such',\n",
       " 'as',\n",
       " 'his',\n",
       " '.',\n",
       " 'And',\n",
       " 'yet',\n",
       " 'there',\n",
       " 'was',\n",
       " 'but',\n",
       " 'one',\n",
       " 'woman',\n",
       " 'to',\n",
       " 'him',\n",
       " ',',\n",
       " 'and',\n",
       " 'that',\n",
       " 'woman',\n",
       " 'was',\n",
       " 'the',\n",
       " 'late',\n",
       " 'Irene',\n",
       " 'Adler',\n",
       " ',',\n",
       " 'of',\n",
       " 'dubious',\n",
       " 'and',\n",
       " 'questionable',\n",
       " 'memory',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word tokenization with spacy\n",
    "# The NLTK package only has word tokenization for English.\n",
    "# spaCy has models for several other languages: Chinese, Danish, Dutch, English, French, German, Greek, Italian, Japanese, Lithuanian, Norwegian, Polish, Portuguese, Romanian, and Spanish. In order to use those models, you would have to download them separately\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(text)\n",
    "words = [token.text for token in doc]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('To', 'ADP'),\n",
       " ('Sherlock', 'PROPN'),\n",
       " ('Holmes', 'PROPN'),\n",
       " ('she', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('always', 'ADV'),\n",
       " ('_', 'PUNCT'),\n",
       " ('the', 'DET'),\n",
       " ('_', 'PROPN'),\n",
       " ('woman', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('I', 'PRON'),\n",
       " ('have', 'AUX'),\n",
       " ('seldom', 'ADV'),\n",
       " ('heard', 'VERB'),\n",
       " ('him', 'PRON'),\n",
       " ('mention', 'VERB'),\n",
       " ('her', 'PRON'),\n",
       " ('under', 'ADP'),\n",
       " ('any', 'DET'),\n",
       " ('other', 'ADJ'),\n",
       " ('name', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('In', 'ADP'),\n",
       " ('his', 'PRON'),\n",
       " ('eyes', 'NOUN'),\n",
       " ('she', 'PRON'),\n",
       " ('eclipses', 'VERB'),\n",
       " ('and', 'CCONJ'),\n",
       " ('predominates', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('whole', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('her', 'PRON'),\n",
       " ('sex', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('It', 'PRON'),\n",
       " ('was', 'AUX'),\n",
       " ('not', 'PART'),\n",
       " ('that', 'SCONJ'),\n",
       " ('he', 'PRON'),\n",
       " ('felt', 'VERB'),\n",
       " ('any', 'DET'),\n",
       " ('emotion', 'NOUN'),\n",
       " ('akin', 'ADJ'),\n",
       " ('to', 'PART'),\n",
       " ('love', 'VERB'),\n",
       " ('for', 'ADP'),\n",
       " ('Irene', 'PROPN'),\n",
       " ('Adler', 'PROPN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('All', 'DET'),\n",
       " ('emotions', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('and', 'CCONJ'),\n",
       " ('that', 'DET'),\n",
       " ('one', 'NUM'),\n",
       " ('particularly', 'ADV'),\n",
       " (',', 'PUNCT'),\n",
       " ('were', 'AUX'),\n",
       " ('abhorrent', 'ADJ'),\n",
       " ('to', 'ADP'),\n",
       " ('his', 'PRON'),\n",
       " ('cold', 'ADJ'),\n",
       " (',', 'PUNCT'),\n",
       " ('precise', 'ADJ'),\n",
       " ('but', 'CCONJ'),\n",
       " ('admirably', 'ADV'),\n",
       " ('balanced', 'ADJ'),\n",
       " ('mind', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('He', 'PRON'),\n",
       " ('was', 'AUX'),\n",
       " (',', 'PUNCT'),\n",
       " ('I', 'PRON'),\n",
       " ('take', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " (',', 'PUNCT'),\n",
       " ('the', 'DET'),\n",
       " ('most', 'ADV'),\n",
       " ('perfect', 'ADJ'),\n",
       " ('reasoning', 'NOUN'),\n",
       " ('and', 'CCONJ'),\n",
       " ('observing', 'VERB'),\n",
       " ('machine', 'NOUN'),\n",
       " ('that', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('world', 'NOUN'),\n",
       " ('has', 'AUX'),\n",
       " ('seen', 'VERB'),\n",
       " (',', 'PUNCT'),\n",
       " ('but', 'CCONJ'),\n",
       " ('as', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('lover', 'NOUN'),\n",
       " ('he', 'PRON'),\n",
       " ('would', 'AUX'),\n",
       " ('have', 'AUX'),\n",
       " ('placed', 'VERB'),\n",
       " ('himself', 'PRON'),\n",
       " ('in', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('false', 'ADJ'),\n",
       " ('position', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('He', 'PRON'),\n",
       " ('never', 'ADV'),\n",
       " ('spoke', 'VERB'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('softer', 'ADJ'),\n",
       " ('passions', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('save', 'VERB'),\n",
       " ('with', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('gibe', 'NOUN'),\n",
       " ('and', 'CCONJ'),\n",
       " ('a', 'DET'),\n",
       " ('sneer', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('They', 'PRON'),\n",
       " ('were', 'AUX'),\n",
       " ('admirable', 'ADJ'),\n",
       " ('things', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('observer', 'NOUN'),\n",
       " ('—', 'PUNCT'),\n",
       " ('excellent', 'ADJ'),\n",
       " ('for', 'ADP'),\n",
       " ('drawing', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('veil', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('men', 'NOUN'),\n",
       " ('’s', 'PART'),\n",
       " ('motives', 'NOUN'),\n",
       " ('and', 'CCONJ'),\n",
       " ('actions', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('But', 'CCONJ'),\n",
       " ('for', 'SCONJ'),\n",
       " ('the', 'DET'),\n",
       " ('trained', 'VERB'),\n",
       " ('reasoner', 'NOUN'),\n",
       " ('to', 'PART'),\n",
       " ('admit', 'VERB'),\n",
       " ('such', 'ADJ'),\n",
       " ('intrusions', 'NOUN'),\n",
       " ('into', 'ADP'),\n",
       " ('his', 'PRON'),\n",
       " ('own', 'ADJ'),\n",
       " ('delicate', 'ADJ'),\n",
       " ('and', 'CCONJ'),\n",
       " ('finely', 'ADV'),\n",
       " ('adjusted', 'VERB'),\n",
       " ('temperament', 'NOUN'),\n",
       " ('was', 'AUX'),\n",
       " ('to', 'PART'),\n",
       " ('introduce', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('distracting', 'VERB'),\n",
       " ('factor', 'NOUN'),\n",
       " ('which', 'PRON'),\n",
       " ('might', 'AUX'),\n",
       " ('throw', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('doubt', 'NOUN'),\n",
       " ('upon', 'SCONJ'),\n",
       " ('all', 'DET'),\n",
       " ('his', 'PRON'),\n",
       " ('mental', 'ADJ'),\n",
       " ('results', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('Grit', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('sensitive', 'ADJ'),\n",
       " ('instrument', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('or', 'CCONJ'),\n",
       " ('a', 'DET'),\n",
       " ('crack', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('one', 'NUM'),\n",
       " ('of', 'ADP'),\n",
       " ('his', 'PRON'),\n",
       " ('own', 'ADJ'),\n",
       " ('high', 'ADJ'),\n",
       " ('-', 'PUNCT'),\n",
       " ('power', 'NOUN'),\n",
       " ('lenses', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('would', 'AUX'),\n",
       " ('not', 'PART'),\n",
       " ('be', 'AUX'),\n",
       " ('more', 'ADV'),\n",
       " ('disturbing', 'ADJ'),\n",
       " ('than', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('strong', 'ADJ'),\n",
       " ('emotion', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('nature', 'NOUN'),\n",
       " ('such', 'ADJ'),\n",
       " ('as', 'ADP'),\n",
       " ('his', 'PRON'),\n",
       " ('.', 'PUNCT'),\n",
       " ('And', 'CCONJ'),\n",
       " ('yet', 'ADV'),\n",
       " ('there', 'PRON'),\n",
       " ('was', 'VERB'),\n",
       " ('but', 'CCONJ'),\n",
       " ('one', 'NUM'),\n",
       " ('woman', 'NOUN'),\n",
       " ('to', 'ADP'),\n",
       " ('him', 'PRON'),\n",
       " (',', 'PUNCT'),\n",
       " ('and', 'CCONJ'),\n",
       " ('that', 'DET'),\n",
       " ('woman', 'NOUN'),\n",
       " ('was', 'AUX'),\n",
       " ('the', 'DET'),\n",
       " ('late', 'ADJ'),\n",
       " ('Irene', 'PROPN'),\n",
       " ('Adler', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('of', 'ADP'),\n",
       " ('dubious', 'ADJ'),\n",
       " ('and', 'CCONJ'),\n",
       " ('questionable', 'ADJ'),\n",
       " ('memory', 'NOUN'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now tag words with their function in the speech\n",
    "words = [token.text for token in doc]\n",
    "pos = [token.pos_ for token in doc]\n",
    "word_pos_tuples = list(zip(words, pos))\n",
    "word_pos_tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['leaf', 'leav', 'book', 'write', 'complet', 'stem', 'sky']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming test\n",
    "from nltk.stem.snowball import SnowballStemmer  # Import nltk stemmer module\n",
    "stemmer = SnowballStemmer('english')  # Set the English language\n",
    "words = ['leaf', 'leaves', 'booking', 'writing', 'completed', 'stemming', 'skies']\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
     ]
    }
   ],
   "source": [
    "# Check which languages are available\n",
    "print(SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting nouns - plural & singular nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "my_filename = \"sherlock_holmes_1.txt\"\n",
    "my_file = open( my_filename, 'r', encoding='utf-8' )\n",
    "text = my_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.11.6 (main, Nov  2 2023, 04:39:43) [Clang 14.0.3 (clang-1403.0.22.14.1)]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing\n",
    "\n",
    "#### As seen on the [Python-Natural-Language-Processing-Cookbook](https://github.com/PacktPublishing/Python-Natural-Language-Processing-Cookbook/tree/master)\n",
    "\n",
    "#### Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tech requirements:\n",
    "# pip install inflect\n",
    "# python -m spacy download en_core_web_md\n",
    "# pip install textacy\n",
    "# pip install neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['duck', 'goose', 'cat', 'book']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization test\n",
    "# lemmatization is similar to stemming, but lemmatization provides us with a real word, the canonical form, instead of the word root like stemming does\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = ['duck', 'geese', 'cats', 'books']\n",
    "\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in reversed(range(10)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fizzbuzz 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Fizz 6\n",
      "7\n",
      "8\n",
      "Fizz 9\n",
      "Buzz 10\n",
      "11\n",
      "Fizz 12\n",
      "13\n",
      "14\n",
      "Fizzbuzz 15\n",
      "16\n",
      "17\n",
      "Fizz 18\n",
      "19\n",
      "Buzz 20\n",
      "Fizz 21\n",
      "22\n",
      "23\n",
      "Fizz 24\n",
      "Buzz 25\n",
      "26\n",
      "Fizz 27\n",
      "28\n",
      "29\n",
      "Fizzbuzz 30\n",
      "31\n",
      "32\n",
      "Fizz 33\n",
      "34\n",
      "Buzz 35\n",
      "Fizz 36\n",
      "37\n",
      "38\n",
      "Fizz 39\n",
      "Buzz 40\n",
      "41\n",
      "Fizz 42\n",
      "43\n",
      "44\n",
      "Fizzbuzz 45\n",
      "46\n",
      "47\n",
      "Fizz 48\n",
      "49\n",
      "Buzz 50\n",
      "Fizz 51\n",
      "52\n",
      "53\n",
      "Fizz 54\n",
      "Buzz 55\n",
      "56\n",
      "Fizz 57\n",
      "58\n",
      "59\n",
      "Fizzbuzz 60\n",
      "61\n",
      "62\n",
      "Fizz 63\n",
      "64\n",
      "Buzz 65\n",
      "Fizz 66\n",
      "67\n",
      "68\n",
      "Fizz 69\n",
      "Buzz 70\n",
      "71\n",
      "Fizz 72\n",
      "73\n",
      "74\n",
      "Fizzbuzz 75\n",
      "76\n",
      "77\n",
      "Fizz 78\n",
      "79\n",
      "Buzz 80\n",
      "Fizz 81\n",
      "82\n",
      "83\n",
      "Fizz 84\n",
      "Buzz 85\n",
      "86\n",
      "Fizz 87\n",
      "88\n",
      "89\n",
      "Fizzbuzz 90\n",
      "91\n",
      "92\n",
      "Fizz 93\n",
      "94\n",
      "Buzz 95\n",
      "Fizz 96\n",
      "97\n",
      "98\n",
      "Fizz 99\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    fizz = (i%5)\n",
    "    buzz = (i%3)\n",
    "\n",
    "    if fizz == 0 and buzz == 0:\n",
    "        print(\"Fizzbuzz\",i)\n",
    "    elif (i%5) == 0 and i > 5:\n",
    "        print('Buzz',i)\n",
    "    elif (i%3) == 0 and i > 3:\n",
    "        print('Fizz',i)\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21 % 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
